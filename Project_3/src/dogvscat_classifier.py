# -*- coding: utf-8 -*-
"""DogVsCat Classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tCBoPKgkiEsJtKOqafvRwVcJPjiF1K-p

# Dog vs Cat Convolution Neural Network Classifier

In this Project, Convolution Neural Network(CNN) Classifier for Classifying dog and cat images is implemened. The Total number of images available for training and validation 25,000.
#### 

Dataset Link: https://www.microsoft.com/en-us/download/details.aspx?id=54765

Soruce: https://www.microsoft.com/en-us/download/details.aspx?id=54765

#### Test Train Split
Image training set contain 12500 images for each category. I split those into 80% train and 20% means test Split each class images into 10,000 for train and 2,500 for test.
"""

#Downloading the dataset from web link
!wget "https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip"

#unzip the data
!unzip "/content/kagglecatsanddogs_3367a.zip"

#required libraries for processing images
import os
import matplotlib.pyplot as plt
import glob
import random
from shutil import copyfile

#This path should contains 2 folders (d0gs, cats) with images
SOURCE_PATH = '/content/PetImages/' # IT will be the extracted folder from zip

#Folder names should be like this in the above path or adjust accordingly.
image_folder = ['Cat', 'Dog']
nimgs = {}
for i in image_folder:
    nimages = len(os.listdir(SOURCE_PATH+i+'/'))
    nimgs[i]=nimages
plt.figure(figsize=(16, 8))
plt.bar(range(len(nimgs)), list(nimgs.values()), align='center')
plt.xticks(range(len(nimgs)), list(nimgs.keys()))
plt.title('Distribution of different classes of Dataset')
plt.show()

#creating directories for splitting the data into training and testing
os.mkdir('model_data')

os.mkdir('model_data/train')
os.mkdir('model_data/test')

os.mkdir('model_data/train/Cat')
os.mkdir('model_data/train/Dog')

os.mkdir('model_data/test/Cat')
os.mkdir('model_data/test/Dog')

#function to split the data 
def split_data(SOURCE, TRAINING, VALIDATION, SPLIT_SIZE):
    files = []
    for filename in os.listdir(SOURCE):
        file = SOURCE + filename
        if os.path.getsize(file) > 0:
            files.append(filename)
        else:
            print(filename + " is zero length, so ignoring.")

    training_length = int(len(files) * SPLIT_SIZE)
    valid_length = int(len(files) - training_length)
    shuffled_set = random.sample(files, len(files))
    training_set = shuffled_set[0:training_length]
    valid_set = shuffled_set[training_length:]

    for filename in training_set:
        this_file = SOURCE + filename
        destination = TRAINING + filename
        copyfile(this_file, destination)

    for filename in valid_set:
        this_file = SOURCE + filename
        destination = VALIDATION + filename
        copyfile(this_file, destination)

#defining DIRS for cats/dogs 
CAT_SOURCE_DIR = SOURCE_PATH + 'Cat/'
TRAINING_CAT_DIR = 'model_data/train/Cat/'
VALID_CAT_DIR = 'model_data/test/Cat/'

DOG_SOURCE_DIR = SOURCE_PATH + 'Dog/'
TRAINING_DOG_DIR = 'model_data/train/Dog/'
VALID_DOG_DIR = 'model_data/test/Dog/'

#split the data into 80-20 percent as training and testing
split_size = .8
split_data(CAT_SOURCE_DIR, TRAINING_CAT_DIR, VALID_CAT_DIR, split_size)
split_data(DOG_SOURCE_DIR, TRAINING_DOG_DIR, VALID_DOG_DIR, split_size)

#printing total images for testing
for i in image_folder:
    print('Training {} images are: '.format(i)+str(len(os.listdir('model_data/train/'+i+'/'))))

#printing total images for training
for i in image_folder:
    print('Test {} images are: '.format(i)+str(len(os.listdir('model_data/test/'+i+'/'))))

# plot dog photos from the dogs vs cats dataset
from matplotlib import pyplot
from matplotlib.image import imread
# define location of dataset
folder = "/content/PetImages/Dog/"
# plot first few images
for i in range(9):
	# define subplot
	pyplot.subplot(330 + 1 + i)
	# define filename
	filename = folder + str(i) + '.jpg'
	# load image pixels
	image = imread(filename)
	# plot raw pixel data
	pyplot.imshow(image)
# show the figure
pyplot.show()

# define location of dataset
folder = "/content/PetImages/Cat/"
# plot first few images
for i in range(9):
	# define subplot
	pyplot.subplot(330 + 1 + i)
	# define filename
	filename = folder + str(i) + '.jpg'
	# load image pixels
	image = imread(filename)
	# plot raw pixel data
	pyplot.imshow(image)
# show the figure
pyplot.show()

"""## **CNN MODEL**"""

#importing libraries for CNN model
import tensorflow
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.callbacks import TensorBoard

from warnings import filterwarnings
filterwarnings('ignore')

"""Network Parameter:
* Rectifier Linear Unit 
* Adam optimizer
* Sigmoid on Final output
* Binary CrossEntropy loss
"""

#Architecture for our CNN model
classifier = Sequential()
classifier.add(Conv2D(32,(3,3),input_shape=(128,128,3),activation = 'relu'))
classifier.add(MaxPooling2D(pool_size=(2,2),strides=2)) #if stride not given it equal to pool filter size
classifier.add(Conv2D(32,(3,3),activation = 'relu'))
classifier.add(MaxPooling2D(pool_size=(2,2),strides=2))
classifier.add(Flatten())
classifier.add(Dense(units=256,activation='relu'))
classifier.add(Dense(units=128,activation='relu'))
classifier.add(Dense(units=2,activation='softmax'))
adam = tensorflow.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)
classifier.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])
#tensorboard = TensorBoard(log_dir="logs/{}".format(time()))

"""## Data Augmentation
Using some Data Augmentation techniques (generate more data) for more data and Better results.
* Shearing of images
* Random zoom
* Horizontal flips
"""

train_dir = '/content/model_data/train' # Path to train directory
test_dir = '/content/model_data/test' # Path to validation directory

from tensorflow.keras.preprocessing.image import ImageDataGenerator
train_datagen = ImageDataGenerator(rescale=1./255,
                                   shear_range=0.1,
                                   zoom_range=0.1,
                                   horizontal_flip=True)
test_datagen = ImageDataGenerator(rescale=1./255)

#Training Set
train_set = train_datagen.flow_from_directory(train_dir,
                                             target_size=(128,128),
                                             batch_size=32,
                                             class_mode='categorical')
#Validation Set
test_set = test_datagen.flow_from_directory(test_dir,
                                           target_size=(128,128),
                                           batch_size = 32,
                                           class_mode='categorical',
                                           shuffle=False)
#Test Set /no output available
test_set1 = test_datagen.flow_from_directory(test_dir,
                                           target_size=(128,128),
                                            batch_size=32,
                                            shuffle=False)

##capture
classifier.fit(train_set, steps_per_epoch=150,epochs=50,validation_data=test_set)


# classifier.fit_generator(train_set,
#                         steps_per_epoch=100, 
#                         epochs = 200,
#                         validation_data = test_set,
#                         #validation_steps = 20, 
#                         verbose =1,
#                         #callbacks=[tensorboard]
#                         );

classifier.save('/content/model_data/dogcat_model_bak.h5')

from tensorflow.keras.models import load_model
classifier = load_model('/content/model_data/dogcat_model_bak.h5')

"""### Prediction of Single Image"""

# Commented out IPython magic to ensure Python compatibility.
#Prediction of image
# %matplotlib inline
import tensorflow
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import numpy as np
img1 = image.load_img('/content/model_data/train/Cat/10049.jpg', target_size=(128, 128))
img = image.img_to_array(img1)
img = img/255
# create a batch of size 1 [N,H,W,C]
img = np.expand_dims(img, axis=0)
prediction = classifier.predict(img, batch_size=None,steps=1) #gives all class prob.
print(prediction)
if(prediction[:,1]>0.6):
    value ='Dog :%1.2f'%(prediction[0,0])
    plt.text(20, 62,value,color='red',fontsize=18,bbox=dict(facecolor='white',alpha=0.8))
elif(prediction[:,0]>0.6):
    value ='Cat :%1.2f'%(1.0-prediction[0,0])
    plt.text(20, 62,value,color='red',fontsize=18,bbox=dict(facecolor='white',alpha=0.8))
else:
    value ='None'
    plt.text(20, 62,value,color='red',fontsize=18,bbox=dict(facecolor='white',alpha=0.8))

plt.imshow(img1)
plt.show()

# for generator image set u can use 

fig=plt.figure(figsize=(15, 6))
columns = 7
rows = 3
for i in range(columns*rows):
    fig.add_subplot(rows, columns, i+1)
    img1 = image.load_img('test1/'+test_set1.filenames[np.random.choice(range(12500))], target_size=(64, 64))
    img = image.img_to_array(img1)
    img = img/255
    img = np.expand_dims(img, axis=0)
    prediction = classifier.predict(img, batch_size=None,steps=1) #gives all class prob.
    if(prediction[:,:]>0.5):
        value ='Dog :%1.2f'%(prediction[0,0])
        plt.text(20, 58,value,color='red',fontsize=10,bbox=dict(facecolor='white',alpha=0.8))
    else:
        value ='Cat :%1.2f'%(1.0-prediction[0,0])
        plt.text(20, 58,value,color='red',fontsize=10,bbox=dict(facecolor='white',alpha=0.8))
    plt.imshow(img1)

# Commented out IPython magic to ensure Python compatibility.
# %%
# # Model Accuracy
# x1 = classifier.evaluate_generator(train_set)
# x2 = classifier.evaluate_generator(test_set)

print('Training Accuracy  : %1.2f%%     Training loss  : %1.6f'%(x1[1]*100,x1[0]))
print('Validation Accuracy: %1.2f%%     Validation loss: %1.6f'%(x2[1]*100,x2[0]))